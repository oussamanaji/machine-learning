{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Hybrid Movie Recommender System\n",
        "\n",
        "Author: Mohamed Oussama Naji\n",
        "\n",
        "Date: March 29, 2024"
      ],
      "metadata": {
        "id": "FwlOlE09sC6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, we will build a hybrid movie recommender system that combines content-based filtering and collaborative filtering techniques. The recommender system aims to provide personalized movie recommendations to users based on their preferences and the preferences of similar users. We will use the MovieLens 20M dataset, which contains movie ratings and tags, to train and evaluate our recommender system.\n"
      ],
      "metadata": {
        "id": "GkdZjVJnsExQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "<a href=\"#installation-setup\">1. Installation and Setup</a><br>\n",
        "<a href=\"#data-loading-preprocessing\">2. Data Loading and Preprocessing</a><br>\n",
        "<a href=\"#popularity-based-recommendation\">3. Popularity-based Recommendation</a><br>\n",
        "<a href=\"#content-based-filtering\">4. Content-based Filtering</a><br>\n",
        "<a href=\"#collaborative-filtering\">5. Collaborative Filtering</a><br>\n",
        "<a href=\"#hybrid-recommender-function\">6. Hybrid Recommender Function</a><br>\n",
        "<a href=\"#testing-evaluation\">7. Testing and Evaluation</a><br>\n",
        "<a href=\"#conclusion\">8. Conclusion</a><br>"
      ],
      "metadata": {
        "id": "eWIvoyOXsJ5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and Setup <a id=\"installation-setup\"></a>\n",
        "\n",
        "Installing the necessary library."
      ],
      "metadata": {
        "id": "Onzcfnl9sLnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "3DkKuL9msM8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing <a id=\"data-loading-preprocessing\"></a>\n",
        "\n",
        "Downloading and loading the MovieLens 20M dataset"
      ],
      "metadata": {
        "id": "GSFRPLrBsOdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
        "!unzip ml-20m.zip"
      ],
      "metadata": {
        "id": "YlcTXVJosRmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary libraries"
      ],
      "metadata": {
        "id": "1TU6T6BZsTDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset, Reader, SVD\n",
        "\n",
        "import cupy as cp\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "agRfLgF9sVjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and preprocessing the relevant data"
      ],
      "metadata": {
        "id": "JvGf1fl9sXIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('ml-20m/movies.csv')\n",
        "ratings = pd.read_csv('ml-20m/ratings.csv')\n",
        "tags = pd.read_csv('ml-20m/tags.csv')\n",
        "\n",
        "tags['tag'] = tags['tag'].astype(str)\n",
        "tags = tags.groupby('movieId')['tag'].apply(' '.join).reset_index()\n",
        "movies = movies.merge(tags, on='movieId', how='left').fillna('')"
      ],
      "metadata": {
        "id": "m5nmh0l2sZnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning"
      ],
      "metadata": {
        "id": "UcJ_ZRcUsb7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_movie_ids = np.unique(np.concatenate([movies['movieId'].unique(), ratings['movieId'].unique()]))\n",
        "\n",
        "valid_ratings = ratings[ratings['movieId'].isin(all_movie_ids)]\n",
        "valid_ratings = valid_ratings.dropna(subset=['userId', 'movieId'])\n",
        "valid_ratings = valid_ratings.drop_duplicates(subset=['userId', 'movieId'])\n",
        "\n",
        "valid_user_ids = valid_ratings['userId'].unique()"
      ],
      "metadata": {
        "id": "9VxS3lXKseQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Popularity-based Recommendation <a id=\"popularity-based-recommendation\"></a>"
      ],
      "metadata": {
        "id": "BNC2sMtasgI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings = valid_ratings.groupby('movieId')['rating'].count().reset_index().sort_values('rating', ascending=False).reset_index(drop=True)\n",
        "popular_movies = movie_ratings[:20]['movieId'].tolist()"
      ],
      "metadata": {
        "id": "zDVtaCfSshuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content-based Filtering <a id=\"content-based-filtering\"></a>\n"
      ],
      "metadata": {
        "id": "OMwvqRU5sj_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['tag'])\n",
        "svd = TruncatedSVD(n_components=10)\n",
        "latent_matrix_1 = svd.fit_transform(tfidf_matrix)"
      ],
      "metadata": {
        "id": "Qa2YZe2pslZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative Filtering <a id=\"collaborative-filtering\"></a>\n"
      ],
      "metadata": {
        "id": "gXT-5QCZsmye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 5000000\n",
        "num_users = len(valid_user_ids)\n",
        "num_movies = len(all_movie_ids)\n",
        "ratings_matrix_chunks = []\n",
        "total_chunks = len(range(0, len(valid_ratings), chunk_size))\n",
        "\n",
        "for i, start in enumerate(range(0, len(valid_ratings), chunk_size)):\n",
        "    chunk = valid_ratings.iloc[start:start+chunk_size]\n",
        "    valid_chunk = chunk[chunk['userId'].isin(valid_user_ids)]\n",
        "    pivot_chunk = valid_chunk.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
        "    pivot_chunk = pivot_chunk.reindex(columns=all_movie_ids, fill_value=0)\n",
        "    chunk_matrix = csr_matrix((pivot_chunk.shape[0], num_movies), dtype=np.float32)\n",
        "\n",
        "    for col_id in pivot_chunk.columns:\n",
        "        if col_id < chunk_matrix.shape[1]:\n",
        "            chunk_matrix[:, col_id] = csr_matrix(pivot_chunk[col_id].values.reshape(-1, 1))\n",
        "\n",
        "    chunk_matrix_gpu = cp.sparse.csr_matrix(chunk_matrix)\n",
        "    ratings_matrix_chunks.append(chunk_matrix_gpu)\n",
        "    print(f\"Progress: {((i + 1) / total_chunks) * 100:.2f}% complete\")\n",
        "\n",
        "ratings_matrix_gpu = cp.sparse.vstack(ratings_matrix_chunks, format='csr')\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(valid_ratings[['userId', 'movieId', 'rating']], reader)\n",
        "model_svd = SVD()\n",
        "model_svd.fit(data.build_full_trainset())\n",
        "latent_matrix_2 = model_svd.pu"
      ],
      "metadata": {
        "id": "_w7OLCPxsqNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Recommender Function <a id=\"hybrid-recommender-function\"></a>"
      ],
      "metadata": {
        "id": "u8YafFONsrre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommender(user_id, movies, ratings, latent_matrix_1, latent_matrix_2, ratings_matrix_gpu, popular_movies, batch_size=100):\n",
        "    user_ratings = ratings[ratings['userId'] == user_id]\n",
        "    watched_movies = user_ratings['movieId'].tolist()\n",
        "    unwatched_movies = movies[~movies['movieId'].isin(watched_movies)]\n",
        "\n",
        "    latent_matrix_1_gpu = cp.asarray(latent_matrix_1)\n",
        "\n",
        "    content_recommendations = []\n",
        "    for start_idx in range(0, len(unwatched_movies), batch_size):\n",
        "        end_idx = min(start_idx + batch_size, len(unwatched_movies))\n",
        "        batch = unwatched_movies.iloc[start_idx:end_idx]\n",
        "        batch_indices = batch.index.tolist()\n",
        "\n",
        "        content_sim_scores = cp.asnumpy(cp.dot(latent_matrix_1_gpu, latent_matrix_1_gpu[batch_indices].T).max(axis=1))\n",
        "        batch_recommendations = list(zip(batch['movieId'].values, content_sim_scores))\n",
        "        content_recommendations.extend(batch_recommendations)\n",
        "\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    content_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_content_recommendations = content_recommendations[:10]\n",
        "\n",
        "    mf_recommendations = []\n",
        "    for movie_id in unwatched_movies['movieId']:\n",
        "        predicted_score = model_svd.predict(user_id, movie_id).est\n",
        "        mf_recommendations.append((movie_id, predicted_score))\n",
        "\n",
        "    mf_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_mf_recommendations = mf_recommendations[:10]\n",
        "\n",
        "    combined_recommendations = top_content_recommendations + top_mf_recommendations\n",
        "    combined_recommendations = list(dict.fromkeys(combined_recommendations))\n",
        "    combined_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return combined_recommendations[:10]"
      ],
      "metadata": {
        "id": "LAl0kJRksuL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and Evaluation <a id=\"testing-evaluation\"></a>\n",
        "\n",
        "Generating and displaying personalized movie recommendations for a specific user."
      ],
      "metadata": {
        "id": "LA-CLcaWsvuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 1\n",
        "recommendations = hybrid_recommender(user_id, movies, ratings, latent_matrix_1, latent_matrix_2, ratings_matrix_gpu, popular_movies)\n",
        "print(f\"Recommendations for user {user_id}:\")\n",
        "for movie_id, score in recommendations:\n",
        "    print(f\"{movies[movies['movieId'] == movie_id]['title'].values[0]}: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "D90R7A8NszAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion <a id=\"conclusion\"></a>\n",
        "\n",
        "In this notebook, we built a hybrid movie recommender system that combines content-based filtering and collaborative filtering techniques. We used the MovieLens 20M dataset to train and evaluate our recommender system.\n",
        "\n",
        "The content-based filtering approach utilized TF-IDF vectorization and Singular Value Decomposition (SVD) to create latent representations of movies based on their tags. The collaborative filtering approach employed matrix factorization using the Surprise library's SVD algorithm to learn latent factors for users and movies.\n",
        "\n",
        "The hybrid recommender function combined the recommendations from both content-based and collaborative filtering approaches, ensuring diversity in the recommended movies. We also incorporated popularity-based recommendations to provide a baseline for comparison.\n",
        "\n",
        "The testing and evaluation section demonstrated the generation of personalized movie recommendations for a specific user. The recommender system successfully provided a list of movies that align with the user's preferences and the preferences of similar users.\n",
        "\n",
        "To further improve the recommender system, we can explore additional techniques such as item-based collaborative filtering, incorporating user and item metadata, and applying more advanced machine learning algorithms. Additionally, we can conduct more extensive evaluation and validation to assess the quality and effectiveness of the recommendations.\n",
        "\n",
        "Overall, this notebook serves as a foundation for building a hybrid movie recommender system and can be extended and customized based on specific requirements and available data."
      ],
      "metadata": {
        "id": "3qcTuhZws2Qo"
      }
    }
  ]
}