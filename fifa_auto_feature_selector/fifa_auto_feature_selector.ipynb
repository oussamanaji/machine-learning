{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AutoFeatureSelector Tool\n",
        "\n",
        "Author: Mohamed Oussama NAJI\n",
        "\n",
        "Date: Jan 26, 2024"
      ],
      "metadata": {
        "id": "74Em1uNkPEF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates the implementation of an Automatic Feature Selection tool using various feature selection methods. The tool is designed to select the best features from a real-world dataset, specifically the FIFA 19 Player Skills dataset. The feature selection methods used include Pearson Correlation, Chi-Square, Recursive Feature Elimination (RFE), Embedded (Logistic Regression), Tree-based (Random Forest), and Tree-based (Light GBM).\n"
      ],
      "metadata": {
        "id": "RM0H92j_PHiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "1. [Dataset Overview](#dataset-overview)\n",
        "2. [Data Preprocessing](#data-preprocessing)\n",
        "3. [Feature Selection Methods](#feature-selection-methods)\n",
        "   - [Pearson Correlation](#pearson-correlation)\n",
        "   - [Chi-Square](#chi-square)\n",
        "   - [Recursive Feature Elimination (RFE)](#recursive-feature-elimination)\n",
        "   - [Embedded (Logistic Regression)](#embedded-logistic-regression)\n",
        "   - [Tree-based (Random Forest)](#tree-based-random-forest)\n",
        "   - [Tree-based (Light GBM)](#tree-based-light-gbm)\n",
        "4. [AutoFeatureSelector Tool](#autofeature-selector-tool)\n",
        "5. [Conclusion](#conclusion)\n"
      ],
      "metadata": {
        "id": "BfSLUU7kPIDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Overview <a id=\"dataset-overview\"></a>\n",
        "\n",
        "The FIFA 19 Player Skills dataset contains attributes of FIFA 2019 players, including age, nationality, overall rating, potential, club, value, wage, preferred foot, international reputation, weak foot, skill moves, work rate, position, and various skill ratings such as crossing, finishing, heading accuracy, short passing, volleys, dribbling, curve, free kick accuracy, long passing, ball control, acceleration, sprint speed, agility, reactions, balance, shot power, jumping, stamina, strength, long shots, aggression, interceptions, positioning, vision, penalties, composure, marking, standing tackle, sliding tackle, goalkeeper diving, goalkeeper handling, goalkeeper kicking, goalkeeper positioning, and goalkeeper reflexes.\n"
      ],
      "metadata": {
        "id": "uvUwSxzrPMzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as ss\n",
        "from collections import Counter\n",
        "import math\n",
        "from scipy import stats\n",
        "\n",
        "player_df = pd.read_csv(\"fifa19.csv\")"
      ],
      "metadata": {
        "id": "RiL10HRnPSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing <a id=\"data-preprocessing\"></a>"
      ],
      "metadata": {
        "id": "kEaW6envPUWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numcols = ['Overall', 'Crossing', 'Finishing', 'ShortPassing', 'Dribbling', 'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility', 'Stamina', 'Volleys', 'FKAccuracy', 'Reactions', 'Balance', 'ShotPower', 'Strength', 'LongShots', 'Aggression', 'Interceptions']\n",
        "catcols = ['Preferred Foot', 'Position', 'Body Type', 'Nationality', 'Weak Foot']\n",
        "\n",
        "player_df = player_df[numcols + catcols]\n",
        "\n",
        "traindf = pd.concat([player_df[numcols], pd.get_dummies(player_df[catcols])], axis=1)\n",
        "\n",
        "# Remove 'Nationality' related columns\n",
        "traindf = traindf[[col for col in traindf.columns if not col.startswith('Nationality_')]]\n",
        "\n",
        "features = traindf.columns\n",
        "\n",
        "traindf = traindf.dropna()\n",
        "\n",
        "traindf = pd.DataFrame(traindf, columns=features)\n",
        "\n",
        "y = traindf['Overall'] >= 87\n",
        "X = traindf.copy()\n",
        "del X['Overall']\n",
        "\n",
        "X.head()\n",
        "\n",
        "len(X.columns)\n",
        "\n",
        "feature_name = list(X.columns)\n",
        "num_feats = 30"
      ],
      "metadata": {
        "id": "vqpw3xZyPY77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection Methods <a id=\"feature-selection-methods\"></a>"
      ],
      "metadata": {
        "id": "NSW5iNxiPbL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pearson Correlation <a id=\"pearson-correlation\"></a>"
      ],
      "metadata": {
        "id": "ao4YkPfYPcm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cor_selector(X, y, num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    cor_feature = X.iloc[:, np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "\n",
        "    return cor_support, cor_feature\n",
        "\n",
        "cor_support, cor_feature = cor_selector(X, y, num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "Rw6k5L_BPedo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chi-Square <a id=\"chi-square\"></a>"
      ],
      "metadata": {
        "id": "7uVeNE3qPf6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def chi_squared_selector(X, y, num_feats):\n",
        "    X_norm = MinMaxScaler().fit_transform(X)\n",
        "    chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "    chi_selector.fit(X_norm, y)\n",
        "\n",
        "    chi_support = chi_selector.get_support()\n",
        "    chi_feature = X.loc[:, chi_support].columns.tolist()\n",
        "\n",
        "    return chi_support, chi_feature\n",
        "\n",
        "chi_support, chi_feature = chi_squared_selector(X, y, num_feats)\n",
        "print(str(len(chi_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "LIurowzkPiM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recursive Feature Elimination (RFE) <a id=\"recursive-feature-elimination\"></a>"
      ],
      "metadata": {
        "id": "xdnEmWhPPjtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def rfe_selector(X, y, num_feats):\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    logreg = LogisticRegression()\n",
        "    rfe = RFE(estimator=logreg, n_features_to_select=num_feats)\n",
        "    rfe.fit(X_scaled, y)\n",
        "\n",
        "    rfe_support = rfe.get_support()\n",
        "    rfe_feature = X.columns[rfe_support].tolist()\n",
        "\n",
        "    return rfe_support, rfe_feature\n",
        "\n",
        "rfe_support, rfe_feature = rfe_selector(X, y, num_feats)\n",
        "print(str(len(rfe_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "WJVcgthEPl_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedded (Logistic Regression) <a id=\"embedded-logistic-regression\"></a>"
      ],
      "metadata": {
        "id": "3CwMFGzBPma6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def embedded_log_reg_selector(X, y, num_feats):\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    logreg = LogisticRegression(penalty='l1', solver='saga', max_iter=1000)\n",
        "\n",
        "    embedded_lr_selector = SelectFromModel(logreg, max_features=num_feats)\n",
        "    embedded_lr_selector.fit(X_scaled, y)\n",
        "\n",
        "    embedded_lr_support = embedded_lr_selector.get_support()\n",
        "    embedded_lr_feature = X.loc[:, embedded_lr_support].columns.tolist()\n",
        "\n",
        "    return embedded_lr_support, embedded_lr_feature\n",
        "\n",
        "embedded_lr_support, embedded_lr_feature = embedded_log_reg_selector(X, y, num_feats)\n",
        "print(str(len(embedded_lr_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "7dfqOCPAPqFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree-based (Random Forest) <a id=\"tree-based-random-forest\"></a>"
      ],
      "metadata": {
        "id": "JEZee0Z8Pr1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def embedded_rf_selector(X, y, num_feats):\n",
        "    rf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "    embedded_rf_selector = SelectFromModel(rf, max_features=num_feats)\n",
        "    embedded_rf_selector.fit(X, y)\n",
        "\n",
        "    embedded_rf_support = embedded_rf_selector.get_support()\n",
        "    embedded_rf_feature = X.loc[:, embedded_rf_support].columns.tolist()\n",
        "\n",
        "    return embedded_rf_support, embedded_rf_feature\n",
        "\n",
        "embedded_rf_support, embedded_rf_feature = embedded_rf_selector(X, y, num_feats)\n",
        "print(str(len(embedded_rf_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "bnNI6ElIPtqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree-based (Light GBM) <a id=\"tree-based-light-gbm\"></a>"
      ],
      "metadata": {
        "id": "Cj114bw2Pu0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "def embedded_lgbm_selector(X, y, num_feats):\n",
        "    lgbm = LGBMClassifier(n_estimators=100)\n",
        "\n",
        "    embedded_lgbm_selector = SelectFromModel(lgbm, max_features=num_feats)\n",
        "    embedded_lgbm_selector.fit(X, y)\n",
        "\n",
        "    embedded_lgbm_support = embedded_lgbm_selector.get_support()\n",
        "    embedded_lgbm_feature = X.loc[:, embedded_lgbm_support].columns.tolist()\n",
        "\n",
        "    return embedded_lgbm_support, embedded_lgbm_feature\n",
        "\n",
        "embedded_lgbm_support, embedded_lgbm_feature = embedded_lgbm_selector(X, y, num_feats)\n",
        "print(str(len(embedded_lgbm_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "zME5sQeRPxD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoFeatureSelector Tool <a id=\"autofeature-selector-tool\"></a>"
      ],
      "metadata": {
        "id": "cObGlcqRPzQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "feature_selection_df = pd.DataFrame({'Feature': feature_name, 'Pearson': cor_support, 'Chi-2': chi_support, 'RFE': rfe_support, 'Logistics': embedded_lr_support,\n",
        "                                     'Random Forest': embedded_rf_support, 'LightGBM': embedded_lgbm_support})\n",
        "\n",
        "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
        "\n",
        "feature_selection_df = feature_selection_df.sort_values(['Total', 'Feature'], ascending=False)\n",
        "feature_selection_df.index = range(1, len(feature_selection_df) + 1)\n",
        "feature_selection_df.head(num_feats)"
      ],
      "metadata": {
        "id": "Eyl_Lt-LQB6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(dataset_path):\n",
        "    player_df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Drop unwanted columns related to nationality\n",
        "    player_df.drop(player_df.filter(regex='(?i)nationality').columns, axis=1, inplace=True)\n",
        "\n",
        "    numcols = ['Overall', 'Crossing', 'Finishing', 'ShortPassing', 'Dribbling', 'LongPassing', 'BallControl',\n",
        "               'Acceleration', 'SprintSpeed', 'Agility', 'Stamina', 'Volleys', 'FKAccuracy', 'Reactions',\n",
        "               'Balance', 'ShotPower', 'Strength', 'LongShots', 'Aggression', 'Interceptions']\n",
        "\n",
        "    catcols = ['Preferred Foot', 'Position', 'Body Type', 'Weak Foot']\n",
        "\n",
        "    player_df = player_df[numcols + catcols]\n",
        "\n",
        "    traindf = pd.concat([player_df[numcols], pd.get_dummies(player_df[catcols])], axis=1)\n",
        "    features = traindf.columns\n",
        "    traindf = traindf.dropna()\n",
        "\n",
        "    X = traindf.copy()\n",
        "    y = X['Overall'] >= 87\n",
        "    del X['Overall']\n",
        "\n",
        "    num_feats = 30\n",
        "\n",
        "    return X, y, num_feats\n",
        "\n",
        "def autoFeatureSelector(dataset_path, methods=[]):\n",
        "    feature_selection_dict = {}\n",
        "\n",
        "    X, y, num_feats = preprocess_dataset(dataset_path)\n",
        "\n",
        "    if 'pearson' in methods:\n",
        "        feature_selection_dict['pearson'] = cor_selector(X, y, num_feats)\n",
        "\n",
        "    if 'chi-square' in methods:\n",
        "        feature_selection_dict['chi-square'] = chi_squared_selector(X, y, num_feats)\n",
        "\n",
        "    if 'rfe' in methods:\n",
        "        feature_selection_dict['rfe'] = rfe_selector(X, y, num_feats)\n",
        "\n",
        "    if 'log-reg' in methods:\n",
        "        feature_selection_dict['log-reg'] = embedded_log_reg_selector(X, y, num_feats)\n",
        "\n",
        "    if 'rf' in methods:\n",
        "        feature_selection_dict['rf'] = embedded_rf_selector(X, y, num_feats)\n",
        "\n",
        "    if 'lgbm' in methods:\n",
        "        feature_selection_dict['lgbm'] = embedded_lgbm_selector(X, y, num_feats)\n",
        "\n",
        "    def debug_feature_lengths(X, feature_selection_dict):\n",
        "        print(\"Number of features in the preprocessed dataset:\", X.shape[1])\n",
        "        for method, (support, _) in feature_selection_dict.items():\n",
        "            print(f\"Number of selected features by {method}:\", len(support))\n",
        "            if len(support) != X.shape[1]:\n",
        "                print(f\"Warning: Mismatch in feature length for {method}\")\n",
        "\n",
        "    debug_feature_lengths(X, feature_selection_dict)\n",
        "\n",
        "    results_dict = feature_selection_dict\n",
        "\n",
        "    pd.set_option('display.max_rows', None)\n",
        "\n",
        "    display_df = pd.DataFrame({'Feature': feature_name})\n",
        "\n",
        "    for method, (support, _) in results_dict.items():\n",
        "        display_df[method] = support\n",
        "\n",
        "    display_df['Total'] = display_df.iloc[:, 1:].sum(axis=1)\n",
        "\n",
        "    display_df = display_df.sort_values(['Total', 'Feature'], ascending=False)\n",
        "    display_df.index = range(1, len(display_df) + 1)\n",
        "    display(display_df.head(num_feats))\n",
        "    best_features = feature_selection_dict\n",
        "    return best_features\n",
        "\n",
        "best_features = autoFeatureSelector(dataset_path=\"fifa19.csv\", methods=['pearson', 'chi-square', 'rfe', 'log-reg', 'rf', 'lgbm'])\n",
        "best_features"
      ],
      "metadata": {
        "id": "Cwg0JJRTP5Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion <a id=\"conclusion\"></a>\n",
        "\n",
        "In this notebook, we developed an Automatic Feature Selection tool that employs various feature selection methods to select the best features from the FIFA 19 Player Skills dataset. The tool combines the results of different feature selection methods, including Pearson Correlation, Chi-Square, Recursive Feature Elimination (RFE), Embedded (Logistic Regression), Tree-based (Random Forest), and Tree-based (Light GBM).\n",
        "\n",
        "The feature selection process involved data preprocessing, where unwanted columns were removed, and categorical features were encoded using one-hot encoding. The target variable was defined based on the 'Overall' rating of the players.\n",
        "\n",
        "The autoFeatureSelector function takes the dataset path and a list of desired feature selection methods as input. It applies each specified method to the preprocessed dataset and returns the selected features for each method. The results are then consolidated into a DataFrame, which displays the selected features and their corresponding support from each method.\n",
        "\n",
        "The tool provides flexibility in choosing the desired feature selection methods and the number of features to select. It helps in identifying the most relevant features for the given dataset and can be used as a starting point for further analysis or modeling tasks.\n",
        "\n",
        "Overall, the Automatic Feature Selection tool simplifies the process of feature selection by automating the application of multiple methods and providing a consolidated view of the selected features. It can be a valuable addition to the data scientist's toolkit for efficient and effective feature selection."
      ],
      "metadata": {
        "id": "pYM3_cF6P-0l"
      }
    }
  ]
}